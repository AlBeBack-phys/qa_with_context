# QA-система с контекстом
# Описание модели

## Предобученная модель

В качестве предобученной модели была взята [ruBERT-base](https://huggingface.co/DeepPavlov/rubert-base-cased). Модель обучалась на датасете [SberQuAD](https://huggingface.co/datasets/kuznetsoffandrey/sberquad) в течение 10 эпох.

## Описание работы модели

Модель классифицирует текст на предмет того, есть ли в нём ответ на заданный вопрос или нет. Для классификации используется токен начала последовательности. Трансформер ruBert с помощью механизма внимания кладёт в этот вектор информацию о том, есть ли в данном тексте ответ на заданный вопрос, затем он прогоняется через бинарный классификатор. Данные для классификатора были аугментированы с использованием идеи negative sampling: для данного контекста брался случайный вопрос из всего имеющегося корпуса. Считалось, что с огромной долей вероятности ответа на сэмплированный вопрос в данном контексте нет.

Ответ на вопрос искался следующим образом:
1. Решалась задача классификации с количеством классов, равным количеству токенов в последовательности, для предсказания токена начала ответа.
2. Все токены до предсказанного начала ответа маскировались.
3. Аналогичным образом предсказывался токен конца ответа.

## Работа с длинными текстами

Модель ruBERT-base имеет ограничение на количество входных токенов — 512. Для решения проблемы обработки длинных текстов, текст разбивается на несколько частей. Однако если ответ находится на стыке двух частей, это может привести к некорректной работе модели.

Чтобы избежать этой проблемы, я использую скользящее окно размера 512 (с учётом длины вопроса) с шагом 256 токенов. Таким образом, все части текста корректно обрабатываются.

Выход классификатора наличия ответа в данном куске текста (число от 0 до 1) интерпретируется как уверенность модели. Если ответ на вопрос был найден в нескольких частях текста, за окончательный ответ берётся тот, где классификатор дал наибольшую уверенность.

## Структура файлов

- `train_model.ipynb` — содержит код, с помощью которого обучалась модель.
- `inference_model.ipynb` — содержит код для использования модели для обработки новых текстов.
- `experiments.ipynb` — содержит наблюдения по работе модели и выводы.

## Взаимодействие через Telegram-бота

Вы также можете взаимодействовать с моделью через Telegram-бота: [Question_GURU_bot](https://t.me/Question_GURU_bot).
